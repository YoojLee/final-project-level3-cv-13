{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as nnf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "workers = 0 if os.name == 'nt' else 4\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범례 한글 깨짐 현상 해결\n",
    "# https://ehpub.co.kr/47-matplotlib%EC%9D%98-rc%EC%97%90-%ED%95%9C%EA%B8%80-%ED%8F%B0%ED%8A%B8%EB%A5%BC-%EC%84%A4%EC%A0%95%ED%95%A0-%EC%88%98-%EC%9E%88%EC%96%B4%EC%9A%94/\n",
    "# https://koosco.tistory.com/38\n",
    "plt.rc('font', family='NanumGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_do_list : 각 폴더에 맞게 수정하면서 사용하다가 이후에 .py 파일로 변경시 상대경로로 바꿔야 할 듯!#\n",
    "\n",
    "# data_path: 연예인 폴더들을 포함하는 상위 폴더\n",
    "actor_data_path = \"/opt/ml/embedding_visualization/data/actor_data\"\n",
    "\n",
    "# embedding_saving_path: embedding vector 변수가 저장되는 파일 위치\n",
    "actor_embedding_saving_path = \"/opt/ml/embedding_visualization/data/actor_embedding_saving.data\"\n",
    "\n",
    "# embedding_info_path: embedding vector에 해당하는 이미지 경로정보가 저장되는 파일 위치\n",
    "actor_embedding_info_path = \"/opt/ml/embedding_visualization/data/actor_embedding_info.data\"\n",
    "\n",
    "# resize_img_path : tensorboard에서 img visualization을 위해 사용하는 img가 저장되는 파일 위치\n",
    "actor_tensorboard_img_path = \"/opt/ml/embedding_visualization/data/actor_tensorboard_img.data\"\n",
    "\n",
    "# webtoon_data_path : 웹툰 폴더들을 포함하는 상위 폴더\n",
    "webtoon_data_path = \"/opt/ml/embedding_visualization/data/webtoon\"\n",
    "\n",
    "# embedding_saving_path: embedding vector 변수가 저장되는 파일 위치\n",
    "webtoon_embedding_saving_path = \"/opt/ml/embedding_visualization/data/webtoon_embedding_saving.data\"\n",
    "\n",
    "# embedding_info_path: embedding vector에 해당하는 이미지 경로정보가 저장되는 파일 위치\n",
    "webtoon_embedding_info_path = \"/opt/ml/embedding_visualization/data/webtoon_embedding_info.data\"\n",
    "\n",
    "# webtoon_img_path : tensorboard에서 webtoon img visualization을 위해 사용하는 img가 저장되는 파일 위치\n",
    "webtoon_tensorboard_img_path = \"/opt/ml/embedding_visualization/data/webtoon_tensorboard_img.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_embeddings 로드\n",
    "with open(actor_embedding_saving_path, 'rb') as f:\n",
    "    actor_embeddings = pickle.load(f)\n",
    "# actor_path_infos 로드\n",
    "with open(actor_embedding_info_path, 'rb') as f:\n",
    "    actor_path_infos = pickle.load(f)\n",
    "# actor_tensorboard_img 로드\n",
    "with open(actor_tensorboard_img_path, 'rb') as f:\n",
    "    actor_tensorboard_img = pickle.load(f)\n",
    "\n",
    "# webtoon_embeddings 로드\n",
    "with open(webtoon_embedding_saving_path, 'rb') as f:\n",
    "    webtoon_embeddings = pickle.load(f)\n",
    "# webtoon_path_infos 로드\n",
    "with open(webtoon_embedding_info_path, 'rb') as f:\n",
    "    webtoon_path_infos = pickle.load(f)\n",
    "# webtoon_tensorboard_img 로드\n",
    "with open(webtoon_tensorboard_img_path, 'rb') as f:\n",
    "    webtoon_tensorboard_img = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/embedding_visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(actor_embeddings) = 19702\n",
    "actor_tensorboard_embeddings = torch.tensor(actor_embeddings[:200])\n",
    "actor_tensorboard_img = actor_tensorboard_img[:200]\n",
    "actor_tensorboard_names = [name for name,file_name in actor_path_infos[:200]]  \n",
    "\n",
    "# len()\n",
    "webtoon_tensorboard_embeddings = torch.tensor(webtoon_embeddings[:200])\n",
    "webtoon_tensorboard_img = webtoon_tensorboard_img[:200]\n",
    "webtoon_tensorboard_names = [name for name,file_name in webtoon_path_infos[:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensorboard_embeddings = torch.cat([actor_tensorboard_embeddings,webtoon_tensorboard_embeddings],dim = 0)\n",
    "output_tensorboard_img = torch.cat([actor_tensorboard_img , webtoon_tensorboard_img],dim=0)\n",
    "output_tensorboard_names = actor_tensorboard_names + webtoon_tensorboard_names\n",
    "\n",
    "print(output_tensorboard_embeddings.shape)\n",
    "print(np.shape(output_tensorboard_img))\n",
    "print(np.shape(output_tensorboard_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 265장 -> 1.6s\n",
    "tsne = TSNE(2, verbose=-1)\n",
    "tsne_proj = tsne.fit_transform(np.array(output_tensorboard_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범례 한글 깨짐 현상 해결\n",
    "# https://ehpub.co.kr/47-matplotlib%EC%9D%98-rc%EC%97%90-%ED%95%9C%EA%B8%80-%ED%8F%B0%ED%8A%B8%EB%A5%BC-%EC%84%A4%EC%A0%95%ED%95%A0-%EC%88%98-%EC%9E%88%EC%96%B4%EC%9A%94/\n",
    "# https://koosco.tistory.com/38\n",
    "plt.rc('font', family='NanumGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "num_categories = len(set(output_tensorboard_names))\n",
    "cmap = matplotlib.cm.get_cmap('Set1', num_categories)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "for i,lab in enumerate(set(output_tensorboard_names)):\n",
    "    indices = np.array(output_tensorboard_names)==lab\n",
    "    # ax.scatter(tsne_proj[indices,0],tsne_proj[indices,1], c=np.array(cmap(i)).reshape(1,4), label = lab ,alpha=0.5)\n",
    "    ax.scatter(tsne_proj[indices,0], tsne_proj[indices,1], cmap=cmap, label=lab ,alpha=0.5)\n",
    "\n",
    "\n",
    "ax.legend(fontsize='large', markerscale=2, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_embedding(output_tensorboard_embeddings, # 400명 embedding 결과\n",
    "                    metadata=output_tensorboard_names,\n",
    "                    label_img=output_tensorboard_img,\n",
    "                    global_step=None\n",
    "                    )\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop된 face image 원본처럼 시각화 (MTCNN은 output을 normalize된 채로 output으로 내보냄!)\n",
    "row_size = 10\n",
    "col_size = min(10, math.ceil(len(output_tensorboard_img[:100])//row_size))\n",
    "fig, ax = plt.subplots(row_size, col_size, figsize=(25, 25)) \n",
    "for i, output in enumerate(output_tensorboard_img[150:250]):\n",
    "    ax[i//row_size][i%col_size].imshow((output * 128 + 127.5).cpu().numpy().astype(np.Uint64).transpose((1,2,0)))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e31c68abf1d5dd3f9e2269f23eadf1b199587e56c0618a30760176a65ebfcab4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
