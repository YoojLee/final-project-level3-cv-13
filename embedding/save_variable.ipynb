{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 파일은 추후 특정 input 이미지에 대해 전체 연예인 embedding vector과의 거리를 계산할 때,<br/>시간 단축을 위해 전체 연예인 embedding vector, 일부 웹툰 embedding vector 관련 정보를 따로 파일로 저장해두는 과정입니다.\n",
    "\n",
    "저장되는 정보는 크게 2개이며 이는 아래와 같습니다.<br/>\n",
    "**(1) embedding vector**<br/>\n",
    "type: np.array<br/>\n",
    "`연예인` shape: (19708, 512)<br/>\n",
    "*19708은 crop 결과물 개수<br/>\n",
    "`웹툰` shape : (352,512)<br/>\n",
    "*352는 웹툰 image 전체 개수<br/><br/>\n",
    "**(2) 이미지 경로**<br/>\n",
    "type: list<br/>\n",
    "`연예인`<br/>\n",
    "각 원소의 형태: [연예인 폴더명, 이미지 파일명]<br/>\n",
    "len: 19708<br/>\n",
    "*19708은 crop 결과물 개수<br/>\n",
    "`웹툰`<br/>\n",
    "각 원소의 형태: [웹툰 폴더명, 웹툰 파일명]<br/>\n",
    "len: 352<br/>\n",
    "*352는 웹툰 image 전체 개수<br/><br/>\n",
    "사용자가 직접 변수값을 입력해줘야 하는 부분은<br/>**0.변수설정**입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as nnf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "workers = 0 if os.name == 'nt' else 4\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.변수설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path: 연예인 폴더들을 포함하는 상위 폴더\n",
    "actor_data_path = \"/opt/ml/embedding_visualization/data/actor_data\"\n",
    "\n",
    "# actor_embedding_saving_path: embedding vector 변수가 저장되는 파일 위치\n",
    "actor_embedding_saving_path = \"/opt/ml/embedding_visualization/data/actor_embedding_saving.data\"\n",
    "\n",
    "# actor_embedding_info_path: embedding vector에 해당하는 이미지 경로정보가 저장되는 파일 위치\n",
    "actor_embedding_info_path = \"/opt/ml/embedding_visualization/data/actor_embedding_info.data\"\n",
    "\n",
    "# actor_tensorboard_img_path : tensorboard에서 img visualization을 위해 사용하는 img가 저장되는 파일 위치\n",
    "actor_tensorboard_img_path = \"/opt/ml/embedding_visualization/data/actor_tensorboard_img.data\"\n",
    "\n",
    "# webtoon_data_path : 웹툰 폴더들을 포함하는 상위 폴더\n",
    "webtoon_data_path = \"/opt/ml/embedding_visualization/data/webtoon\"\n",
    "\n",
    "# webtoon_embedding_saving_path: embedding vector 변수가 저장되는 파일 위치\n",
    "webtoon_embedding_saving_path = \"/opt/ml/embedding_visualization/data/webtoon_embedding_saving.data\"\n",
    "\n",
    "# webtoon_embedding_info_path: embedding vector에 해당하는 이미지 경로정보가 저장되는 파일 위치\n",
    "webtoon_embedding_info_path = \"/opt/ml/embedding_visualization/data/webtoon_embedding_info.data\"\n",
    "\n",
    "# webtoon_tensorboard_img_path : tensorboard에서 webtoon img visualization을 위해 사용하는 img가 저장되는 파일 위치\n",
    "webtoon_tensorboard_img_path = \"/opt/ml/embedding_visualization/data/webtoon_tensorboard_img.data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. MTCNN 모듈 및 InceptionResnetV1 모듈 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 사진이 없는 폴더 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연예인 사진이 없는 경우 해당 폴더는 crop대상에서 제외\n",
    "actor_names = []\n",
    "remove_actor_names = []\n",
    "for actor_name in os.listdir(actor_data_path):\n",
    "    file_path = os.path.join(actor_data_path, actor_name)\n",
    "    if os.path.isdir(file_path):\n",
    "        if len(os.listdir(file_path)) > 0: # 해당 폴더에 사진이 있는 경우\n",
    "            actor_names.append(actor_name)\n",
    "        else:                              # 해당 폴더에 사진이 없는 경우\n",
    "            remove_actor_names.append(actor_name)\n",
    "\n",
    "print(f'사진이 존재하는 배우: {len(actor_names)}명') # 818명\n",
    "print(f'사진이 존재하지 않는 배우(삭제될 배우): {len(remove_actor_names)}명') # 5명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹툰 사진이 없는 경우 해당 폴더는 crop대상에서 제외\n",
    "webtoon_names = []\n",
    "remove_webtoon_names = []\n",
    "for webtoon_name in os.listdir(webtoon_data_path):\n",
    "    file_path = os.path.join(webtoon_data_path, webtoon_name)\n",
    "    if os.path.isdir(file_path):\n",
    "        if len(os.listdir(file_path)) > 0: # 해당 폴더에 사진이 있는 경우\n",
    "            webtoon_names.append(webtoon_name)\n",
    "        else:                              # 해당 폴더에 사진이 없는 경우\n",
    "            remove_webtoon_names.append(webtoon_name)\n",
    "\n",
    "print(f'사진이 존재하는 웹툰: {len(webtoon_names)}명') # 9명\n",
    "print(f'사진이 존재하지 않는 웹툰(삭제될 웹툰): {len(remove_webtoon_names)}명') # 0명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Crop을 위한 custom Dataset정의 및 Data로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_path, select_names):\n",
    "        self.mtcnn = mtcnn\n",
    "        self.imgs, self.labels, self.paths, self.idx_to_class = self.make_dataset(data_path, select_names)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        label = self.labels[idx]\n",
    "        path = self.paths[idx]\n",
    "        return img, label, path\n",
    "\n",
    "    def make_dataset(self, data_path, select_names):\n",
    "        imgs = []\n",
    "        labels = []\n",
    "        paths = []\n",
    "        idx_to_class = {key:name for key, name in enumerate(select_names)}\n",
    "        for key, name in idx_to_class.items():\n",
    "            actor_path = os.path.join(data_path, name)\n",
    "            for img_name in os.listdir(actor_path):\n",
    "                # img의 차원이 3이 아니거나, 채널의 개수가 3이 아닌 경우 제외\n",
    "                img_path = os.path.join(actor_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if type(img) == np.ndarray and len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    imgs.append(img)\n",
    "                    labels.append(key)\n",
    "                    paths.append(img_path)\n",
    "\n",
    "        return imgs, labels, paths, idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total data 실행속도: 1m30s 내외\n",
    "actor_dataset = CustomImageDataset(actor_data_path, actor_names)\n",
    "webtoon_dataset = CustomImageDataset(webtoon_data_path, webtoon_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'actor crop 대상 이미지 개수: {len(actor_dataset.imgs)}') # 19725\n",
    "print(f'actor len(labels): {len(actor_dataset.labels)}') # 19725\n",
    "print(f'actor dataset.idx_to_class: {actor_dataset.idx_to_class}') # 818\n",
    "print()\n",
    "print(f'webtoon crop 대상 이미지 개수: {len(webtoon_dataset.imgs)}') # 352\n",
    "print(f'webtoon len(labels): {len(webtoon_dataset.labels)}') # 352\n",
    "print(f'webtoon dataset.idx_to_class: {webtoon_dataset.idx_to_class}') # 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "actor_loader = DataLoader(actor_dataset, collate_fn=collate_fn, num_workers=workers, batch_size=1)\n",
    "webtoon_loader = DataLoader(webtoon_dataset, collate_fn=collate_fn, num_workers=workers, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Crop 수행 및 수행결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19725장 -> 14m \n",
    "# crop결과물 19708개\n",
    "actor_aligned = [] # tensor 형태의 face crop image\n",
    "actor_names = [] # list 형태의 actor name\n",
    "actor_img_names = [] # img_names 형태의 actor file name\n",
    "actor_tensorboard_img = [] # tensor 형태의 3x50x50 face crop image\n",
    "for idx, (x, y, path) in tqdm(enumerate(actor_loader)):\n",
    "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        actor_aligned.append(x_aligned)\n",
    "        x = x_aligned.unsqueeze(0)\n",
    "        actor_tensorboard_img.append(nnf.interpolate(x,size=(50,50)).squeeze(0)) \n",
    "        actor_names.append(actor_dataset.idx_to_class[y])\n",
    "        actor_img_names.append(path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 352장 -> 5s -> interploate때문에 분 정도로 늘어남!\n",
    "webtoon_aligned = [] # tensor 형태의 webtoon image\n",
    "webtoon_names = [] # list 형태의 webtoon name\n",
    "webtoon_img_names = [] # img_names 형태의 webtoon file name\n",
    "webtoon_tensorboard_img = [] # tensor 형태의 3x50x50 webtoon image\n",
    "tf = transforms.ToTensor()\n",
    "for idx, (x, y, path) in tqdm(enumerate(webtoon_loader)):\n",
    "    x = tf(x).unsqueeze(0)\n",
    "    webtoon_aligned.append(nnf.interpolate(x,size=(160,160)).squeeze(0))\n",
    "    webtoon_tensorboard_img.append(nnf.interpolate(x,size=(50,50)).squeeze(0)) \n",
    "    webtoon_names.append(webtoon_dataset.idx_to_class[y])\n",
    "    webtoon_img_names.append(path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped face visualization \n",
    "row_size = 10\n",
    "col_size = min(10, math.ceil(len(webtoon_aligned)//row_size))\n",
    "fig, ax = plt.subplots(row_size, col_size, figsize=(25, 25)) \n",
    "print(len(webtoon_aligned))\n",
    "for i, output in enumerate(webtoon_aligned[:100]): # embedding 되는 웹툰 image\n",
    "    ax[i//col_size][i%col_size].imshow((output*255).cpu().numpy().astype(np.Uint64).transpose((1,2,0)))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop된 face image 원본처럼 시각화 \n",
    "row_size = 10\n",
    "col_size = min(10, math.ceil(len(actor_aligned)//row_size))\n",
    "fig, ax = plt.subplots(row_size, col_size, figsize=(25, 25)) \n",
    "for i, output in enumerate(actor_aligned[:100]):\n",
    "    # (MTCNN은 output을 normalize된 채로 output으로 내보냄!)\n",
    "    ax[i//row_size][i%col_size].imshow((output * 128 + 127.5).cpu().numpy().astype(np.Uint64).transpose((1,2,0)))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Embedding vector 계산을 위한 Dataset정의 및 데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, aligned: list, names: list, img_names: list, tensorboard_img: list):\n",
    "        self.aligned_torch = torch.stack(aligned)\n",
    "        self.names = names\n",
    "        self.img_names = img_names\n",
    "        self.tensorboard_img  = tensorboard_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.aligned_torch)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.aligned_torch[idx], self.names[idx], self.img_names[idx], self.tensorboard_img[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_aligned_dataset = EmbeddingDataset(actor_aligned, actor_names, actor_img_names, actor_tensorboard_img)\n",
    "actor_alinged_loader = DataLoader(actor_aligned_dataset, num_workers=workers, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'stack된 aligned shape: {actor_aligned_dataset.aligned_torch.shape}') # torch.Size([19708, 3, 160, 160])\n",
    "print(f'len(aligned_dataset): {len(actor_aligned_dataset)}') # 19708\n",
    "print(f'len(alinged_loader): {len(actor_alinged_loader)}\\n') # 395\n",
    "\n",
    "print(f'len(names): {len(actor_aligned_dataset.names)}') # 19708\n",
    "print(f'names[0]: {actor_aligned_dataset.names[0]}\\n') # 곽지민\n",
    "\n",
    "print(f'len(img_names): {len(actor_aligned_dataset.img_names)}') # 19708\n",
    "print(f'img_names[0]: {actor_aligned_dataset.img_names[0]}\\n') # 곽지민2.jpg\n",
    "\n",
    "print(f'len(tensorboard_img): {len(actor_tensorboard_img)}') # 19708\n",
    "print(f'tensorboard_img[0].shape: {actor_tensorboard_img[0].shape}') # torch.Size([3, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webtoon_aligned_dataset = EmbeddingDataset(webtoon_aligned, webtoon_names, webtoon_img_names, webtoon_tensorboard_img)\n",
    "webtoon_alinged_loader = DataLoader(webtoon_aligned_dataset, num_workers=workers, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'stack된 aligned shape: {webtoon_aligned_dataset.aligned_torch.shape}') # torch.Size([352, 3, 160, 160])\n",
    "print(f'len(aligned_dataset): {len(webtoon_aligned_dataset)}') # 352\n",
    "print(f'len(alinged_loader): {len(webtoon_alinged_loader)}\\n') # 8\n",
    "\n",
    "print(f'len(names): {len(webtoon_aligned_dataset.names)}') # 352\n",
    "print(f'names[0]: {webtoon_aligned_dataset.names[0]}\\n') # Unknown1\n",
    "\n",
    "print(f'len(img_names): {len(webtoon_aligned_dataset.img_names)}') # 352\n",
    "print(f'img_names[0]: {webtoon_aligned_dataset.img_names[0]}\\n') # 4422_pp_0.jpg\n",
    "\n",
    "print(f'len(tensorboard_img): {len(webtoon_tensorboard_img)}') # 352\n",
    "print(f'tensorboard_img[0].shape: {webtoon_tensorboard_img[0].shape}') # torch.Size([3, 50, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. InceptionResnetV1 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19708장 -> 16.3s\n",
    "actor_saving_embeddings = []\n",
    "actor_saving_names = []\n",
    "actor_saving_img_names = []\n",
    "actor_saving_tensorboard_img = torch.stack(actor_tensorboard_img).to(device)\n",
    "for x, name, img_name, tensorboard_img in actor_alinged_loader:\n",
    "    embedding = resnet(x.to(device))\n",
    "    actor_saving_embeddings.extend(embedding.detach().cpu().tolist())\n",
    "    actor_saving_names.extend(name)\n",
    "    actor_saving_img_names.extend(img_name)\n",
    "\n",
    "actor_saving_img_infos = list(map(list, zip(actor_saving_names, actor_saving_img_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'actor embedding shape: {np.array(actor_saving_embeddings).shape}') # (19708, 512)\n",
    "print(f'actor len(saving_img_infos): {len(actor_saving_names)}') # 19708\n",
    "print(f'actor saving_img_infos[0]: {actor_saving_img_infos[0]}') # ['곽지민', '곽지민2.jpg'] example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 392장 -> \n",
    "webtoon_saving_embeddings = []\n",
    "webtoon_saving_names = []\n",
    "webtoon_saving_img_names = []\n",
    "webtoon_saving_tensorboard_img = torch.stack(webtoon_tensorboard_img).to(device)\n",
    "for x, name, img_name, tensorboard_img in webtoon_alinged_loader:\n",
    "    embedding = resnet(x.to(device))\n",
    "    webtoon_saving_embeddings.extend(embedding.detach().cpu().tolist())\n",
    "    webtoon_saving_names.extend(name)\n",
    "    webtoon_saving_img_names.extend(img_name)\n",
    "\n",
    "webtoon_saving_img_infos = list(map(list, zip(webtoon_saving_names, webtoon_saving_img_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'webtoon embedding shape: {np.array(webtoon_saving_embeddings).shape}') # (352, 512)\n",
    "print(f'webtoon len(saving_img_infos): {len(webtoon_saving_names)}') # 352\n",
    "print(f'webtoon saving_img_infos[0]: {webtoon_saving_img_infos[0]}') # ['Unknown1', '4422_pp_0.jpg'] example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. pickle 저장 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### actor 관련 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_saving_embeddings 저장\n",
    "with open(actor_embedding_saving_path, 'wb') as f:\n",
    "    pickle.dump(actor_saving_embeddings, f)\n",
    "# actor_saving_img_infos 저장\n",
    "with open(actor_embedding_info_path, 'wb') as f:\n",
    "    pickle.dump(actor_saving_img_infos, f)\n",
    "# actor_saving_tensorboard_img 저장\n",
    "with open(actor_tensorboard_img_path, 'wb') as f:\n",
    "    pickle.dump(actor_saving_tensorboard_img, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### webtoon 관련 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webtoon_saving_embeddings 저장\n",
    "with open(webtoon_embedding_saving_path, 'wb') as f:\n",
    "    pickle.dump(webtoon_saving_embeddings, f)\n",
    "# webtoon_saving_img_infos 저장\n",
    "with open(webtoon_embedding_info_path, 'wb') as f:\n",
    "    pickle.dump(webtoon_saving_img_infos, f)\n",
    "# webtoon_saving_tensorboard_img 저장\n",
    "with open(webtoon_tensorboard_img_path, 'wb') as f:\n",
    "    pickle.dump(webtoon_saving_tensorboard_img, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
